<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
	<head>
		<meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Cinder</title>
		<link rel="stylesheet" href="cinder_doxygen.css" type="text/css" media="screen" />
	</head>
<body>	
<div class="wrapper">
	<div id="header">
		<h1><a href="http://libcinder.org">Cinder</a></h1>
	</div>

<!-- Generated by Doxygen 1.7.1 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Chapter 3: Face Detection </h1>  </div>
</div>
<div class="contents">
<h2><a class="anchor" id="Introduction"></a>
Introduction</h2>
<p>One of the most well known features of OpenCV is its functionality for detecting faces. Let's look at how this works by launching the ocvFaceDetect sample located at <em>blocks/openCV/samples/ocvFaceDetect</em>. You should see an image in your webcam similar to the one below, assuming you are two young women standing underneath an umbrella in Amsterdam. I am not, so I used a <a href="http://www.flickr.com/photos/stuckincustoms/225004025/">photograph by Trey Ratcliff</a>.<br/>
 <br/>
 </p>
<div align="center">
<img src="ch3_result.jpg" alt="ch3_result.jpg"/>
</div>
<p> <br/>
 You'll note that the bounding rectangles of the two faces in the image are highlighted in yellow, and their eyes are marked with transparent blue circles. Let's take a look at how this is achieved, starting with the sample's setup() routine.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvFaceDetectApp::setup()
{
<span class="preprocessor">#if defined( CINDER_MAC )</span>
<span class="preprocessor"></span>    mFaceCascade.load( getResourcePath( <span class="stringliteral">&quot;haarcascade_frontalface_alt.xml&quot;</span> ) );
    mEyeCascade.load( getResourcePath( <span class="stringliteral">&quot;haarcascade_eye.xml&quot;</span> ) );   
<span class="preprocessor">#else</span>
<span class="preprocessor"></span>    mFaceCascade.load( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#af65a96bbb3d641719942cd5540dcc8c4">getAppPath</a>() + <span class="stringliteral">&quot;../../resources/haarcascade_frontalface_alt.xml&quot;</span> );
    mEyeCascade.load( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#af65a96bbb3d641719942cd5540dcc8c4">getAppPath</a>() + <span class="stringliteral">&quot;../../resources/haarcascade_eye.xml&quot;</span> );   
<span class="preprocessor">#endif</span>
<span class="preprocessor"></span>    
    mCapture = Capture( 640, 480 );
    mCapture.start();
}
</pre></div><p> <br/>
 First, a bit of platform-specific code. In order to initialize our <a href="http://opencv.willowgarage.com/documentation/cpp/object_detection.html#cascadeclassifier"><code>cv::CascadeClassifier</code></a>s <em>mFaceCascade</em> and <em>mEyeCascade</em>, we need to pass a file path for the XML descriptors. The way Mac OS X uses resources makes this easy, since resources are simply files inside the application bundle. We just call <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/classcinder_1_1app_1_1_app.html#aaa00fb529a7c8eadb32d1bf912c4d181">app::App::getResourcePath()</a>. However resources under Windows work differently, as they are not individual files but instead are binary baked directly into the .exe itself. In the ocvFaceDetect sample we do not include these XML descriptors as true resources, but instead determine their file path relative to the application by using <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#af65a96bbb3d641719942cd5540dcc8c4">app::getAppPath()</a>.<br/>
 <br/>
 Speaking of these XML descriptors, what exactly are they? Simply put, these are mathematical descriptions of what constitutes a feature of a certain variety - frontal faces in the first, and human eyes in the second. Both of these descriptors come with OpenCV, and it is also possible to create your own descriptors. If you are interested in knowing more of the specifics, you might read <a href="http://opencv.willowgarage.com/wiki/FaceDetection">Face Detection using OpenCV</a>, or the Wikipedia page on <a href="http://en.wikipedia.org/wiki/Viola-Jones_object_detection_framework">Viola-Jones object detection framework</a>. For now though we just need to understand that Haar Cascade Classifiers are created using a large database of images and can identify particular features.<br/>
 <br/>
 Following the initialization of these classifiers, we fire up the webcam. Now let's move on to the sample's most interesting section, the updateFaces() function.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvFaceDetectApp::updateFaces( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a7f62055e4cb811edb9868b32595a1d64">Surface</a> cameraImage )
{
    <span class="keyword">const</span> <span class="keywordtype">int</span> calcScale = 2; <span class="comment">// calculate the image at half scale</span>

    <span class="comment">// create a grayscale copy of the input image</span>
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> grayCameraImage( toOcv( cameraImage, CV_8UC1 ) );

    <span class="comment">// scale it to half size, as dictated by the calcScale constant</span>
    <span class="keywordtype">int</span> scaledWidth = cameraImage.getWidth() / calcScale;
    <span class="keywordtype">int</span> scaledHeight = cameraImage.getHeight() / calcScale; 
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> smallImg( scaledHeight, scaledWidth, CV_8UC1 );
    <a class="code" href="namespacecv.html#a499709bf0b1c163796c1a7e6bc18e7c2">cv::resize</a>( grayCameraImage, smallImg, smallImg.size(), 0, 0, cv::INTER_LINEAR );
    
    <span class="comment">// equalize the histogram</span>
    <a class="code" href="namespacecv.html#ac2dcc16eef7f4c229d85940793fc4ed2">cv::equalizeHist</a>( smallImg, smallImg );
</pre></div><p> <br/>
 <em>cameraImage</em> enters the function as a full resolution, color image - a frame from our webcam. Next, we create a grayscale copy <em>grayCameraImage</em>. By using the optional argument to toOcv(), we can create an 8-bit single channel image. The Cinder OpenCV bridge automatically converts our color input image to a grayscale version. Next, we allocate a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> <em>smallImg</em> to hold a half-sized copy of the input image. By using this smaller image as input to the face detection algorithm, we can improve the performance of the app at a relatively minor cost in precision. This scale is achieved using the <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-resize">cv::resize()</a> routine. Last, we run a process called histogram equalization on the image using <a href="http://opencv.willowgarage.com/documentation/cpp/histograms.html#cv-equalizehist">cv::equalizeHist()</a>. This is a contrast enhancement technique that is designed to improve the accuracy of the feature detection.<br/>
 <br/>
 </p>
<div align="center">
<img src="ch3_process.jpg" alt="ch3_process.jpg"/>
</div>
<p> <br/>
 </p>
<div class="fragment"><pre class="fragment">    <span class="comment">// clear out the previously deteced faces &amp; eyes</span>
    mFaces.clear();
    mEyes.clear();

    <span class="comment">// detect the faces and iterate them, appending them to mFaces</span>
    vector&lt;cv::Rect&gt; faces;
    mFaceCascade.detectMultiScale( smallImg, faces );
    <span class="keywordflow">for</span>( vector&lt;cv::Rect&gt;::const_iterator faceIter = faces.begin(); faceIter != faces.end(); ++faceIter ) {
        <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#ac60c086a9aa8f5320c96da74cbf20f8b">Rectf</a> faceRect( fromOcv( *faceIter ) );
        faceRect *= calcScale;
        mFaces.push_back( faceRect );
        
        <span class="comment">// detect eyes within this face and iterate them, appending them to mEyes</span>
        vector&lt;cv::Rect&gt; eyes;
        mEyeCascade.detectMultiScale( smallImg( *faceIter ), eyes );
        <span class="keywordflow">for</span>( vector&lt;cv::Rect&gt;::const_iterator eyeIter = eyes.begin(); eyeIter != eyes.end(); ++eyeIter ) {
            <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#ac60c086a9aa8f5320c96da74cbf20f8b">Rectf</a> eyeRect( fromOcv( *eyeIter ) );
            eyeRect = eyeRect * calcScale + faceRect.getUpperLeft();
            mEyes.push_back( eyeRect );
        }
    }
}
</pre></div><p> <br/>
 In the second half of updateFaces(), we begin by clearing out our <code>std::vector&lt;&gt;</code> of faces and eyes from the previous frame. We then allocate some temporary storage and make the sample's most important call, <a href="http://opencv.willowgarage.com/documentation/cpp/object_detection.html#cv-cascadeclassifier-detectmultiscale">cv::CascadeClassifier::detectMultiScale()</a>. This function takes a grayscale <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> as input, <em>smallImg</em> in our case, followed by a <code>vector&lt;cv::Rect&gt;</code> for storing the objects it detects. Any detected objects are stored in <em>faces</em>, which we iterate in the for-loop that follows. For each face we scale it back up by <em>calcScale</em> so that it's relative to our input image and append to our <em>mFaces</em> variable. Then, we iterate the bounding box of this face for any eyes it might contain, calling <a href="http://opencv.willowgarage.com/documentation/cpp/object_detection.html#cv-cascadeclassifier-detectmultiscale">detectMultiScale()</a> using our eye classifier this time. Notice the first parameter to this function, <code>smallImg( *faceIter )</code>. This makes use of the <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> constructor which accepts a <a class="el" href="namespacecv.html#a954f5c2ab7c3f0f5d4eed444cdabf038">cv::Rect</a> to create a sub-image of <em>smallImg</em>. This way we aren't searching the entire image for eyes - only the area of this particular face. Before we push each detected eye into our <em>mEyes</em> varaiable, we need to scale it up by <em>calcScale</em>, and since its location is relative to the face in <em>faceIter</em>, we'll need to offset it by the upper-left corner of the current face. That's all there is to it - you've mastered an age-old OpenCV rite of passage, coding a face detector. <br/>
 </p>
<h2>Exercises</h2>
<p>1. <a href="http://opencv.willowgarage.com/documentation/cpp/object_detection.html#cv-cascadeclassifier-detectmultiscale">cv::CascadeClassifier::detectMultiScale()</a> accepts several additional parameters for which we are using the defaults. Checkout the documentation for this function and experiment with these parameters. How do they affect the accuracy of the detector? What about performance? <br/>
 </p>
</div>
	<div class="footer">
		<p> </p>
	</div>
</div>	
</body>
</html>
