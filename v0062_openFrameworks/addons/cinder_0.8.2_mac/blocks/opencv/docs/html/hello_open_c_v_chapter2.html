<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
	<head>
		<meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Cinder</title>
		<link rel="stylesheet" href="cinder_doxygen.css" type="text/css" media="screen" />
	</head>
<body>	
<div class="wrapper">
	<div id="header">
		<h1><a href="http://libcinder.org">Cinder</a></h1>
	</div>

<!-- Generated by Doxygen 1.7.1 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Chapter 2: Image Transformations </h1>  </div>
</div>
<div class="contents">
<h2><a class="anchor" id="Introduction"></a>
Introduction</h2>
<p>In the previous section we looked at manipulating the pixels of an image by operations like blurring or edge detection. Now let's take a look at warping images using transformations. These processes don't modify the content of images, but instead deform them geometrically. OpenCV has a number of functions which do this. First we'll examine the sample which demonstrates the <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a> function. Open up the CinderBlock sample located at <em>blocks/openCV/samples/ocvWarp</em> and run it. You will see a rotated and scaled version of the input image, which is <a href="http://www.flickr.com/photos/stuckincustoms/3899587834">a photograph by Trey Ratcliff</a>.<br/>
<br/>
 </p>
<div align="center">
<img src="warp_warp.jpg" alt="warp_warp.jpg"/>
</div>
<p> <br/>
 <br/>
 </p>
<h2><a class="anchor" id="AffineWarp"></a>
Affine Warping</h2>
<p>Cool - let's explore how this thing works. We'll start with setup:<br/>
<br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvWarpApp::setup()
{       
    mInputImage = ci::Surface8u( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a5091cf493eafbd8741669dfac5188856">loadImage</a>( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#a93522b1858f745f7d9438d6d124ae11b">loadResource</a>( RES_IMAGE ) ) );

    mRotationCenter = mInputImage.getSize() * 0.5f;
    mRotationAngle = 31.2f;
    mScale = 0.77f;
    
    mParams = params::InterfaceGl( <span class="stringliteral">&quot;Parameters&quot;</span>, <a class="code" href="namespacecv.html#a121402b88177c336b18945dd71d96ae0">Vec2i</a>( 200, 400 ) );
    mParams.addParam( <span class="stringliteral">&quot;Rotation Center X&quot;</span>, &amp;mRotationCenter.x );
    mParams.addParam( <span class="stringliteral">&quot;Rotation Center Y&quot;</span>, &amp;mRotationCenter.y );
    mParams.addParam( <span class="stringliteral">&quot;Rotation Angle&quot;</span>, &amp;mRotationAngle );
    mParams.addParam( <span class="stringliteral">&quot;Scale&quot;</span>, &amp;mScale, <span class="stringliteral">&quot;step=0.1&quot;</span> );

    updateImage();
}
</pre></div><p> <br/>
 This should all be familiar. We load our image from a resource and put it in <em>mInputImage</em>. Then we initialize some member variables which are the parameters of our warp: a <em>mRotationCenter</em> that is the center of the image, <em>mRotationAngle</em> of <code>31.2</code> degrees, and a <em>mScale</em> of <code>0.77</code>. Then we build a <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/classcinder_1_1params_1_1_interface_gl.html">params::InterfaceGl</a> to create a GUI for these parameters. Last, we call updateImage(), which is where the interesting OpenCV work happens:<br/>
<br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvWarpApp::updateImage()
{
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> <a class="code" href="ml_8h.html#a8f45a3157cd8bdbb30d638b20fd31f1a">input</a>( toOcv( mInputImage ) );
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> output;

    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> warpMatrix = <a class="code" href="namespacecv.html#acaef7be7ae5d0825cce7e677bf6d6b4f">cv::getRotationMatrix2D</a>( toOcv( mRotationCenter ), mRotationAngle, mScale );
    <a class="code" href="namespacecv.html#a435a37e3b4071e90c97ee3e79d4bbecc">cv::warpAffine</a>( input, output, warpMatrix, toOcv( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#a9926e7943f83caba9b76f49aa6e569d5">getWindowSize</a>() ), <a class="code" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aa55e404e7fa9684af79fe9827f36a5dc1">cv::INTER_CUBIC</a> );

    mTexture = gl::Texture( fromOcv( output ) );
}
</pre></div><p> <br/>
 The first two lines here also are familiar - we're just creating a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> called <em>input</em> which contains our <em>mInputImage</em> and then an empty <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> to hold our <em>output</em>. The next line is new though. It creates a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> as well, not for holding an image, but the mathematical transform we want to apply to each pixel's position. As you may know, matrices are often used to express a series of geometric transformations. <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getrotationmatrix2d">cv::getRotationMatrix2D()</a> is a convenience method which creates the correct transformation matrix to achieve a rotation of degrees <em>mRotationAngle</em> around the point <em>mRotationCenter</em>, all preceeded by a scale of magnitude <em>mScale</em>.<br/>
 <br/>
 In the next line, we make use of this matrix in our call to <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>. You can think of this routine as applying the matrix <em>warpMatrix</em> to each pixel in the input image, assigning it a new position in the output image. In reality, the exact inverse is what happens in order to prevent holes in the output image. OpenCV looks at each pixel in the output image and applies the inverse transformation to identify the source pixel in the input image. If this doesn't quite make sense yet, don't get too caught up in the details - just trust that taking the result of <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getrotationmatrix2d">cv::getRotationMatrix2D()</a> lets us build a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> we can use to warp the image using <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>. Note the final parameter for <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>, which is set to <code><a class="el" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aa55e404e7fa9684af79fe9827f36a5dc1">cv::INTER_CUBIC</a></code> in the example above. This is the interpolation parameter, which (simplifying a bit) tells OpenCV how many surrounding pixels to consider when it calculates each output pixel. Other common values include <code><a class="el" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aaa5521d8e080972c762467c45f3b70e6c">cv::INTER_NEAREST</a></code>, <code><a class="el" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aac97d8e4880d8b5d509e96825c7522deb">cv::INTER_LINEAR</a></code> and <code><a class="el" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aac6c578caa97f2d00f82bac879cf3c781">cv::INTER_LANCZOS4</a></code>. In general using more samples looks nicer (particularly when increasing the size of the image), but is slower. The zoomed screenshots below depict some of the interpolation modes:<br/>
<br/>
 </p>
<div align="center">
<img src="warp_interp.png" alt="warp_interp.png"/>
</div>
<p> <br/>
 </p>
<h2><a class="anchor" id="PerspectiveWarp"></a>
Perspective Warping</h2>
<p><br/>
 Let's pause and consider the <em>affine</em> part of <a class="el" href="namespacecv.html#a435a37e3b4071e90c97ee3e79d4bbecc">cv::warpAffine()</a>'s name. An affine transformation is one made up of rotation, translation and scale (and technically shear, though that is less commonly used). Another way to think of this is that an affine transformation can transform a rectangle into any parallelogram. But what about less rigid transformations? For example, what if I wanted to "pull" the corner of a rectangle somewhere, but leave the other three corners in place? An affine transformation can't create this warp - we need a <em>perspective</em> transformation. Let's take a look at how to achieve this using OpenCV. Open up the CinderBlock sample located at <em>blocks/openCV/samples/ocvPerspective</em>. Go ahead and run the sample - you should see an image about like this one:<br/>
 <br/>
 </p>
<div align="center">
<img src="warp_persp.jpg" alt="warp_persp.jpg"/>
</div>
<p> <br/>
 In the screenshot above we can see a perspective transformation in action, applied to a <a href="http://www.flickr.com/photos/pedrosz/3411746271/">photograph by Pedro Szekely</a>. Let's take a look at the source. Much of it is devoted to interacting with the mouse, allowing you to drag the corners around the window. It maintains an internal array of the four corners, called <em>mPoints</em>. The interesting bit is in ocvPerspectiveApp::updateImage(): </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvPerspectiveApp::updateImage()
{
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> <a class="code" href="ml_8h.html#a8f45a3157cd8bdbb30d638b20fd31f1a">input</a>( toOcv( mInputImage ) ), output;

    <a class="code" href="classcv_1_1_point__.html">cv::Point2f</a> <a class="code" href="cvaux_8h.html#ab4cdd1c16a22344c9f968fca805b5d70">src</a>[4];
    src[0] = <a class="code" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a>( 0, 0 );
    src[1] = <a class="code" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a>( mInputImage.getWidth(), 0 );
    src[2] = <a class="code" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a>( mInputImage.getWidth(), mInputImage.getHeight() );
    src[3] = <a class="code" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a>( 0, mInputImage.getHeight() );
    
    <a class="code" href="classcv_1_1_point__.html">cv::Point2f</a> <a class="code" href="cvaux_8h.html#a630368d4e6b55d40d80e2bd38c87a19f">dst</a>[4];
    <span class="keywordflow">for</span>( <span class="keywordtype">int</span> i = 0; i &lt; 4; ++i )
        dst[i] = toOcv( mPoints[i] );
    
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> warpMatrix = <a class="code" href="namespacecv.html#a57c98631f11caa482f16ea5ec82ed7c7">cv::getPerspectiveTransform</a>( src, dst );
    <a class="code" href="namespacecv.html#a3215a47d3e1cfe9fe27c0b5e8557e50b">cv::warpPerspective</a>( input, output, warpMatrix, toOcv( <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1app.html#a9926e7943f83caba9b76f49aa6e569d5">getWindowSize</a>() ), <a class="code" href="namespacecv.html#a393fbd89880a50a6b584eaa2f646088aa55e404e7fa9684af79fe9827f36a5dc1">cv::INTER_CUBIC</a> );

    mTexture = gl::Texture( fromOcv( output ) );
}
</pre></div><p> <br/>
 Just as <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getrotationmatrix2d">cv::getRotationMatrix2D()</a> generates the right matrix for <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>, for perspective transforms we use <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getperspectivetransform">cv::getPerspectiveTransform()</a> to generate a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> for <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-warpperspective">cv::warpPerspective()</a>. This function takes a two arrays of 4 <code><a class="el" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a></code>'s as input. The first represents the original positions of four corners. In our case, these original points are the corners of our image, which we prepare in the <em>src</em> array, ordered in clockwise order starting with the upper-left corner (0,0). Next, we prepare the <em>dst</em> array, which stores the warped positions of the corresponding four corners. The sample allows users to drag these four corners around with the mouse (represented with the orange dots), so we simply convert these <code>ci::Vec2f</code>'s into <code><a class="el" href="namespacecv.html#a7d080aa40de011e4410bca63385ffe2a">cv::Point2f</a></code>'s using ci::toOcv(). The call to <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getperspectivetransform">cv::getPerspectiveTransform()</a> returns the 3x3 matrix which warps <em>src</em> into <em>dst</em>. We then pass this matrix as input to <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-warpperspective">cv::warpPerspective()</a>, whose parameters are identical to those of <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>. Keep in mind that the resulting <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> is still just a rectangular image, but filled with black everywhere that is outside of the warped input image.</p>
<h2>Exercises</h2>
<p>1. Checkout the <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-resize">cv::resize()</a> routine. How does its performance compare to <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#warpAffine">cv::warpAffine()</a>?<br/>
 2. How does <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-warpperspective">cv::warpPerspective()</a> compare to the texture mapping in OpenGL? Build an app that matches as closely as possible - you can use <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/classcinder_1_1_camera.html#a0807952fe486c6c8b00abb061a014ca5">CameraPersp::worldToScreen()</a> to determine the coordinates for <a href="http://opencv.willowgarage.com/documentation/cpp/geometric_image_transformations.html#cv-getperspectivetransform">cv::getPerspectiveTransform()</a>.<br/>
 <br/>
 </p>
</div>
	<div class="footer">
		<p> </p>
	</div>
</div>	
</body>
</html>
