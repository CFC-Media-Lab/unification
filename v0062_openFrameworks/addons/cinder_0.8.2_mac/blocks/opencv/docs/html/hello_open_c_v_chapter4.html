<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
	<head>
		<meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Cinder</title>
		<link rel="stylesheet" href="cinder_doxygen.css" type="text/css" media="screen" />
	</head>
<body>	
<div class="wrapper">
	<div id="header">
		<h1><a href="http://libcinder.org">Cinder</a></h1>
	</div>

<!-- Generated by Doxygen 1.7.1 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Chapter 4: Statistics </h1>  </div>
</div>
<div class="contents">
<h2><a class="anchor" id="Introduction"></a>
Introduction</h2>
<p>While OpenCV is obviously best known for its computer vision capabilities, it also contains plenty of functionality for things like pure mathematics and computational geometry. We'll take a look at one of these features, a technique called k-means clustering, and then apply it to the classic computer graphics problem of color reduction.<br/>
 <br/>
 Imagine you have a large number of points which are mostly random, but are distributed in a few regions. How do you identify these few regions where the points gather? In the image below, we have the positions of the 2,000 blue dots, but how do we calculate the best positions for the 7 green dots?<br/>
 </p>
<div align="center">
<img src="kmeans_2d_distro.png" alt="kmeans_2d_distro.png"/>
</div>
<p> <br/>
 One family of techniques for tackling this problem is known as <em>clustering algorithms</em>. OpenCV ships with an implementation of a high quality clustering algorithm called <em>k-means clustering</em>. Let's imagine that we have a <code>vector&lt;ci::Vec2f&gt;</code> of known positions and we'd like to write a function which finds the ideal <code>k</code> clusters. Our function signature might look about like this: </p>
<div class="fragment"><pre class="fragment">vector&lt;Vec2f&gt; calculateClusters( <span class="keyword">const</span> vector&lt;Vec2f&gt; &amp;input, <span class="keywordtype">int</span> k );
</pre></div><p> <br/>
 Let's take a look at how we can use OpenCV's k-means implementation to write the body of this function. The heart of this code will be the function <a href="http://opencv.willowgarage.com/documentation/cpp/clustering_and_search_in_multi-dimensional_spaces.html#cv-kmeans">cv::kmeans</a>. <br/>
 </p>
<div class="fragment"><pre class="fragment">vector&lt;Vec2f&gt; calculateClusters( <span class="keyword">const</span> vector&lt;Vec2f&gt; &amp;input, <span class="keywordtype">int</span> k )
{
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> inputMat( input.size(), 1, CV_32FC2 );
    <span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i = 0; i &lt; input.size(); ++i )
        inputMat.at&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec2f</a>&gt;(i,0) = toOcv( input[i] );

    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> <a class="code" href="cxcore_8h.html#a1342f74a0f7dd7c20ab7e79b2e6e5af5">labels</a>, clusters;
    <a class="code" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a>( inputMat, k, labels, <a class="code" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>( <a class="code" href="classcv_1_1_term_criteria.html#ab1c05bdc2ace6e8c53e21d7257a31db9aeb9da694ea67b3ef7d524521b580867d">cv::TermCriteria::COUNT</a>, 10, 0 ),
        12, <a class="code" href="namespacecv.html#a909006d1e0a5688d198d1f1e61059f45adfa80a38dfc0aef0de888c3164f33faf">cv::KMEANS_RANDOM_CENTERS</a>, &amp;clusters );

    vector&lt;Vec2f&gt; <a class="code" href="cvaux_8h.html#adf46fee3107905e425f34254cbce0d9a">result</a>;
    <span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i = 0; i &lt; k; ++i )
        result.push_back( fromOcv( clusters.<a class="code" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">at</a>&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec2f</a>&gt;(i,0) ) );

    <span class="keywordflow">return</span> result;
}
</pre></div><p> <br/>
 Let's go through this code line by line.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment">    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> inputMat( input.size(), 1, CV_32FC2 );
    <span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i = 0; i &lt; input.size(); ++i )
        inputMat.at&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec2f</a>&gt;(i,0) = toOcv( input[i] );
</pre></div><p> <br/>
 The first line allocates a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> <em>inputMat</em> that is <code>input.size()</code> rows tall, and <code>1</code> column wide. Additionally, the <code>CV_32FC2</code> constant requests storage for holding 32-bit floating point values (<code>32F</code>), <code>2</code> channels per "pixel" (the <code>C2</code>). The <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> function wants to receive samples (the blue dots in our case) in this form - a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> that is one column wide and has as many rows as there are samples. The for-loop that follows sets each row of this <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> to the samples we received from the <em>input</em> parameter. Notice the <code>at&lt;cv::Vec2f&gt;()</code> function. This returns a reference to a particular pixel or sample in our case. So <code>inputMat.at&lt;cv::Vec2f&gt;(i,0)</code> returns a reference to the first (and only) "pixel" in the <em>i-th</em> row, and then we set this to each value of our <em>input</em> vector.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><a class="code" href="classcv_1_1_mat.html">cv::Mat</a> labels, clusters;
</pre></div><p> <br/>
 Here we are simply declaring some empty <code><a class="el" href="classcv_1_1_mat.html">cv::Mat</a></code>s which will store our results. We will ignore <em>labels</em> in this example, but <em>clusters</em> will hold the result we are interested in - the green dots.<br/>
 </p>
<div class="fragment"><pre class="fragment">    <a class="code" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a>( inputMat, k, labels, <a class="code" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>( <a class="code" href="classcv_1_1_term_criteria.html#ab1c05bdc2ace6e8c53e21d7257a31db9aeb9da694ea67b3ef7d524521b580867d">cv::TermCriteria::COUNT</a>, 10, 0 ),
        12, <a class="code" href="namespacecv.html#a909006d1e0a5688d198d1f1e61059f45adfa80a38dfc0aef0de888c3164f33faf">cv::KMEANS_RANDOM_CENTERS</a>, &amp;clusters );
</pre></div><p> <br/>
 Next is the heavy lifting, where we call <a href="http://opencv.willowgarage.com/documentation/cpp/clustering_and_search_in_multi-dimensional_spaces.html#cv-kmeans">cv::kmeans</a> itself. First we pass the input samples array <em>inputMat</em>, followed by the number of clusters we are looking for - our <em>k</em> parameter. Next we give the function somewhere to put its output labels - something we are not interested in yet but will use in a later example. The fourth parameter is a <a class="el" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a> or termination criteria. This is a class which allows us to tell OpenCV when its calculation is good enough. The example above tells OpenCV to refine its results <code>10</code> times and call it good. More refinements can result in a more precise result but also take longer. Next is a parameter which tells OpenCV how many times to attempt the algorithm, which we've selected <code>12</code> for. Don't confuse this parameter with the refinement parameter of the <a class="el" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>. The way the k-means algorithm works involves an initial random distribution of cluster centers which are refined according to the <a class="el" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>. This <em>attempts</em> parameter tells OpenCV how many times to start over with different random distributions. It will automatically select the best result from each of these attempts. The next parameter, for which we have selected <code><a class="el" href="namespacecv.html#a909006d1e0a5688d198d1f1e61059f45adfa80a38dfc0aef0de888c3164f33faf">cv::KMEANS_RANDOM_CENTERS</a></code>, tells OpenCV how to do its initial random distribution, and can generally be the constant we are passing here. Finally, we give OpenCV the address of a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> where it can put its results, <em>&amp;clusters</em>.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment">    vector&lt;Vec2f&gt; result;
    <span class="keywordflow">for</span>( <span class="keywordtype">size_t</span> i = 0; i &lt; k; ++i )
        result.push_back( fromOcv( clusters.<a class="code" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">at</a>&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec2f</a>&gt;(i,0) ) );

    <span class="keywordflow">return</span> result;
</pre></div><p> <br/>
 After the <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> call, the function's results are stored in <em>clusters</em>. This <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> will be shaped the same way <em>inputMat</em> was - a one column wide "image" which contains one row per sample. The result image will be <em>k</em> rows tall since that is the number of clusters we've requested. Here we are doing the reverse operation from the one we did to prepare <em>inputMat</em> - pulling out the value of each of the "pixels" in <em>clusters</em> and putting them into a <code>vector&lt;ci::Vec2f&gt;</code>, which we return as the result of the function. Pass these Vec2f's to a series of <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder_1_1gl.html#a225b1296ceeaa8b2393339fc39debf7a">gl::drawSolidCircle()</a> calls and you'll have the image above. <br/>
 </p>
<h2>Putting k-means to work</h2>
<p>OK - this is obviously a powerful technique, but what's an example of something visual we might do with it? The algorithm is good at taking a large sample set, and distilling it down into an ideal smaller sample set. Let's apply that to one of the classic computer graphics problems, color reduction.<br/>
 <br/>
 These days, it's not uncommon to distribute images in full 24-bit color. But it's still a standard technique to reduce the number of colors in an image in order to minimize file size through compression. For example, the popular file format PNG supports special modes that are based on a predetermined color palette. Without getting too deep into the particulars, imagine the advantages of a fixed color palette of say, 16 entries, instead of 24-bit color. We can use 4 bits to encode each pixel (capable of expressing one of our 16 possibilities) instead of 24 bits to express "true color". The question is <em>which</em> 16 colors should we choose? Obviously, the best choices will be different for any given image. Below is an example (created using an <a href="http://www.flickr.com/photos/jaewalk/3133924813/">image from Flickr user <em>jaewalk</em></a>).<br/>
 <br/>
 </p>
<div align="center">
<img src="kmeans_paletted.png" alt="kmeans_paletted.png"/>
</div>
<p> <br/>
 Is there a way we can use k-means to solve this problem? What if we treat each color in the image as a three dimensional sample (red, green &amp; blue) - we can ask k-means for the 16 best samples to represent all of them, creating the ideal color palette for the image. Put another way, think of the color of each pixel in the image as being one of the blue dots from our example above, and the entries of our ideal color palette as being the green dots. Of course this will require us to run the k-means algorithm in 3D instead of 2D, but that's no problem since OpenCV's k-means function can run in any dimension.<br/>
 <br/>
 Let's walk through an implementation of this idea. Open up the CinderBlock sample located at <em>blocks/openCV/samples/ocvColorQuantize</em>. We'll examine this code in detail to understand exactly how the algorithm works.<br/>
 <br/>
 The <code>ocvColorQuantizeApp::setup()</code> and <code>ocvColorQuantizeApp::draw()</code> functions are likely familiar to you, so we'll skip those. The interesting function for our purposes is <code>ocvColorQuantizeApp::updateImage()</code>. Let's take that one from the top.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">void</span> ocvColorQuantizeApp::updateImage()
{
    <span class="keyword">const</span> <span class="keywordtype">int</span> colorCount = 32;
    <span class="keyword">const</span> <span class="keywordtype">int</span> sampleCount = mInputImage.getHeight() * mInputImage.getWidth();
    <a class="code" href="classcv_1_1_mat.html">cv::Mat</a> colorSamples( sampleCount, 1, CV_32FC3 );
</pre></div><p> <br/>
 The first line just declares a constant, which is the size of our color palette. Here we've hardcoded it to look for the <code>32</code> ideal colors. Next, we determine how many samples we'll have (the number of blue pixels in our earlier example) which is the total number of pixels. Next we allocate our <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> which will contain these samples, just as we did in the earlier example. Notice though that we use the <code>CV_32FC3</code> constant. We're asking for a 3D floating point sample, since we'll be passing 3D (red, green &amp; blue) data to k-means.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment">Surface::ConstIter imageIt = mInputImage.getIter();
<a class="code" href="classcv_1_1_mat_iterator__.html">cv::MatIterator_&lt;cv::Vec3f&gt;</a> sampleIt = colorSamples.begin&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec3f</a>&gt;();
<span class="keywordflow">while</span>( imageIt.line() )
    <span class="keywordflow">while</span>( imageIt.pixel() )
        *sampleIt++ = <a class="code" href="classcv_1_1_vec.html">cv::Vec3f</a>( imageIt.r(), imageIt.g(), imageIt.b() );
</pre></div><p> <br/>
 This code is a bit fancier than the 2D example. First we allocate a Surface::ConstIter which we'll use to walk the pixels of our input ci::Surface. Next we allocate a similar iterator for our <a class="el" href="classcv_1_1_mat.html">cv::Mat</a>. You may not have encountered this begin() function before, but it behaves just like <a class="elRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/classcinder_1_1_surface_t.html#a2d33a9fdbb5242e13e27c0dfc7fe7c33">Surface::getIter()</a> does, the difference being the template parameter which tells it what sort of data is contained in the <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> - <a class="el" href="namespacecv.html#ab9e0ab642a3e01742916763173b72232">cv::Vec3f</a> being what's in ours. Next comes the nested while-loops which are standard for iterating pixels in Cinder. The interesting line assigns to our cv::MatIterator a <a class="el" href="namespacecv.html#ab9e0ab642a3e01742916763173b72232">cv::Vec3f</a> we build out of each pixel of the input image.<br/>
 <br/>
 If this seems confusing, you might refer back to the analogous lines in the sample code above. Again, we're just building a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> which is one pixel wide and is as tall as the number of samples we want to pass to <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> - how many blue dots we have. Our "blue dots" are the colors of the input image, which we're treating as 3D data, pretending red-green-blue are x-y-z.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><a class="code" href="classcv_1_1_mat.html">cv::Mat</a> labels, clusters;
<a class="code" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a>( colorSamples, colorCount, labels, <a class="code" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>( <a class="code" href="classcv_1_1_term_criteria.html#ab1c05bdc2ace6e8c53e21d7257a31db9aeb9da694ea67b3ef7d524521b580867d">cv::TermCriteria::COUNT</a>, 8, 0 ), 
        2, <a class="code" href="namespacecv.html#a909006d1e0a5688d198d1f1e61059f45adfa80a38dfc0aef0de888c3164f33faf">cv::KMEANS_RANDOM_CENTERS</a>, &amp;clusters );
</pre></div><p> <br/>
 Next we allocate some space for <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> to put its results and our "labels", which we'll come to in a few lines, and then we call the function. Refer to the earlier code or its documentation if you've forgotten the meaning of the parameters to <a href="http://opencv.willowgarage.com/documentation/cpp/clustering_and_search_in_multi-dimensional_spaces.html#cv-kmeans">cv::kmeans</a>.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a0c860907658a359cf5cfc87639998563">Color8u</a> clusterColors[colorCount];
<span class="keywordflow">for</span>( <span class="keywordtype">int</span> i = 0; i &lt; colorCount; ++i )
    clusterColors[i] = <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a0c860907658a359cf5cfc87639998563">Color8u</a>( clusters.<a class="code" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">at</a>&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec3f</a>&gt;(i,0)[0],
        clusters.<a class="code" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">at</a>&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec3f</a>&gt;(i,0)[1], clusters.<a class="code" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">at</a>&lt;<a class="code" href="classcv_1_1_vec.html">cv::Vec3f</a>&gt;(i,0)[2] );
</pre></div><p> <br/>
 Here we walk the values of the <em>clusters</em> <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> and convert each of its 3D x-y-z values into the r-g-b they were all along. We use the <a class="el" href="classcv_1_1_mat.html#a156c464981100f4ce606ae63a1568663">cv::Mat::at()</a> function. Recall that <em>clusters</em> is where <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> has put its results, and that it is a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> that is one sample wide, and is <em>colorCount</em> rows tall. At the end of the for-loop <em>clusterColors</em> contains our resulting color palette, and if that's all we wanted, we could stop here.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a7f62055e4cb811edb9868b32595a1d64">Surface</a> <a class="code" href="cvaux_8h.html#adf46fee3107905e425f34254cbce0d9a">result</a>( mInputImage.getWidth(), mInputImage.getHeight(), false );
Surface::Iter resultIt = result.getIter();
<a class="code" href="classcv_1_1_mat_iterator__.html">cv::MatIterator_&lt;int&gt;</a> labelIt = labels.<a class="code" href="classcv_1_1_mat.html#a595d7b53cc170519ae1e68e868bb582f">begin</a>&lt;<span class="keywordtype">int</span>&gt;();
<span class="keywordflow">while</span>( resultIt.line() ) {
    <span class="keywordflow">while</span>( resultIt.pixel() ) {
        resultIt.r() = clusterColors[*labelIt].r;
        resultIt.g() = clusterColors[*labelIt].g;
        resultIt.b() = clusterColors[*labelIt].b;
        ++labelIt;
    }
}
</pre></div><p> <br/>
 Our function is designed to create a new image from the input Surface <em>ocvColorQuantizeApp::mInputImage</em> having reassigned each pixel to one of the values in our color palette <em>clusterColors</em>. The first line in this block allocates a new ci::Surface <em>result</em> for this purpose, and creates a Surface::Iter <em>resultIt</em> so that we can assign each pixel one-by-one. Next it creates an iterator to walk the values of <em>labels</em>, a <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> we ignored until this point. Notice that <em>labels</em> was passed to <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> earlier (and in fact it was in our 2D example, but we never made use of it). This is yet another <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> which is one "pixel" wide and in our case, <em>colorSamples</em> tall. Its storage is allocated by <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a> itself, and it corresponds to the values we passed in <em>colorSamples</em>, except each value in the <a class="el" href="classcv_1_1_mat.html">cv::Mat</a> is an index into <em>clusters</em>. Let's unpack that statement using an example. Imagine that the tenth value we passed into <em>colorSamples</em>, being the sample at row 9, column 0 was a nice purple, say RGB(212, 0, 225). And let's imagine that the closest value in our resulting color palette <em>clusters</em> was the 6th entry, since clusters[5] = RGB(201, 14, 212). In this case, the matching tenth value in <em>labels</em> (the one at row 9, column 0) will be <code>5</code> - the appropriate index into <em>clusters</em> to find our best fit color.<br/>
 <br/>
 Knowing that about the value of <em>labels</em>, the rest is straightforward. We use the standard Surface::Iter nested while-loop to walk across the pixels of <em>result</em>, assigning each one the RGB values of <em>clusterColors</em> based on the index we receive from our <em>labels</em> iterator.<br/>
 <br/>
 </p>
<div class="fragment"><pre class="fragment"><span class="keyword">const</span> <span class="keywordtype">int</span> swatchSize = 12;
<span class="keywordflow">for</span>( <span class="keywordtype">int</span> i = 0; i &lt; colorCount; ++i )
    ip::fill( &amp;result, clusterColors[i], <a class="codeRef" doxygen="cinder.tag:../../../../docs/html/" href="../../../../docs/html/namespacecinder.html#a157f7d1781706c0affefe6063e9bd24e">Area</a>( i * swatchSize, result.getHeight() - swatchSize,
            ( i + 1 ) * swatchSize, result.getHeight() ) ); 

mTexture = gl::Texture( result );
</pre></div><p> <br/>
 As a finishing touch, we use the ip::fill routine to draw a little series of swatch squares which depict our color palette in the lower left corner of the image. Finally, we create a gl::Texture <em>mTexture</em> out of our <em>result</em> Surface.<br/>
 <br/>
 </p>
<div align="center">
<img src="kmeans_result.png" alt="kmeans_result.png"/>
</div>
<p> <br/>
 </p>
<h2>Exercises</h2>
<p>1. Consider experimenting with the parameters of the call to <a class="el" href="namespacecv.html#a58d4da15c6e9ef96edbe151a4cf9b702">cv::kmeans</a>. For example, how much does the palette change or improve to pass a higher count to the <a class="el" href="classcv_1_1_term_criteria.html">cv::TermCriteria</a>. What about a larger number of attempts?<br/>
 2. Try designing a version of the ocvColorQuantize sample which can process an entire video clip, and select the ideal palette for a sequence of images.<br/>
 3. Advanced: Read up on dithering algorithms if you aren't familiar. The <a href="http://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering">Floyd-Steinberg algorithm</a> is a classic. Look at implementing this algorithm or a similar one to improve the output of ocvColorQuantize.<br/>
 </p>
</div>
	<div class="footer">
		<p> </p>
	</div>
</div>	
</body>
</html>
